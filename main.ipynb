{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Headline\n",
    "\n",
    "An AI model that creates a haedline or a title of a specific blog post using the content. This models is created using transformers from Hugging Face library and scikit-learn. The data was collected on Kaggle."
   ],
   "metadata": {
    "tags": [],
    "cell_id": "88311ea07b5c426b834126b47e369456",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers==4.26.0"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "e9b060e011b94cadb880c0d97f98de64",
    "source_hash": "717f0504",
    "output_cleared": true,
    "execution_start": 1674738333969,
    "execution_millis": 6588,
    "deepnote_to_be_reexecuted": false,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, DistilBertForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# imported packages correctly?\n",
    "print(\"successfully!\")\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv('/datasets/summaries/data.csv')\n",
    "print(\"Read file\")\n",
    "\n",
    "# sample only 20% of the data\n",
    "data = data.sample(frac=0.1)\n",
    "print(\"Got sample\")\n",
    "\n",
    "# drop missing values\n",
    "data.dropna(inplace=True)\n",
    "print(\"Dropped empty values\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "print(\"split the data sets\")\n",
    "\n",
    "# Extract the summaries and full stories from the training data\n",
    "train_summaries = train_data['Summary']\n",
    "train_stories = train_data['Content']\n",
    "print(\"extracted specific columns from training data\")\n",
    "\n",
    "# Extract the summaries and full stories from the testing data\n",
    "test_summaries = test_data['Summary']\n",
    "test_stories = test_data['Content']\n",
    "print(\"extracted specific columns from testing data\")\n",
    "\n",
    "# Load the pre-trained tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "print(\"created the tokenizer\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "print(\"defined the model\")\n",
    "\n",
    "# Convert the data into input format for the model\n",
    "train_inputs = tokenizer.batch_encode_plus(train_stories.tolist(), max_length=512, pad_to_max_length=True, return_tensors='pt')\n",
    "test_inputs = tokenizer.batch_encode_plus(test_stories.tolist(), max_length=512, pad_to_max_length=True, return_tensors='pt')\n",
    "print(\"tokenizied the training and the testing data\")\n",
    "\n",
    "# Train the model on the training data\n",
    "model.train()\n",
    "print(\"trained the model\")\n",
    "model.zero_grad()\n",
    "print(\"set all the gradients of the model's parameters to zero\")\n",
    "outputs = model(input_ids=train_inputs['input_ids'], labels=train_summaries)\n",
    "print(\"defined the outputs\")\n",
    "loss, logits = outputs[:2]\n",
    "loss.backward()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "optimizer.step()\n",
    "\n",
    "# Test the model on the testing data\n",
    "model.eval()\n",
    "outputs = model(input_ids=test_inputs['input_ids'])\n",
    "predictions = outputs[0]\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(test_summaries, predictions)\n",
    "print('Accuracy:', accuracy)\n"
   ],
   "metadata": {
    "tags": [],
    "cell_id": "e56be40bb9bf463aaac8b7201d0188aa",
    "source_hash": "7717b8b2",
    "output_cleared": true,
    "execution_start": 1674738340561,
    "execution_millis": 1687,
    "deepnote_to_be_reexecuted": false,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=36b8a784-1bd6-47ec-836d-38cd0b38ef5c' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ],
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "deepnote": {},
  "orig_nbformat": 2,
  "deepnote_notebook_id": "ac19a2a2aea04635994cc5481d5efa16",
  "deepnote_execution_queue": []
 }
}
